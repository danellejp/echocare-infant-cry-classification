{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e91725",
   "metadata": {},
   "source": [
    "# EchoCare: Cry Detection Model Training\n",
    "## Stage 1 of Two-Stage Pipeline\n",
    "\n",
    "This notebook trains a binary classification model to detect infant cries vs non-cry sounds.\n",
    "\n",
    "**Dataset:**\n",
    "- Cry sounds: Baby Chillanto Database (normal, hungry, pain)\n",
    "- Non-cry sounds: ESC-50 Dataset\n",
    "\n",
    "**Target Performance:** >85% accuracy for cry detection\n",
    "\n",
    "**Architecture:** MobileNetV2 (lightweight for Raspberry Pi deployment) with custom classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb11e45",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9879099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import cv2\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4ad02",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baa33845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/dataset/processed/mel-spectrograms/cry_detection/train\")\n",
    "val_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/dataset/processed/mel-spectrograms/cry_detection/validate\")\n",
    "test_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/dataset/processed/mel-spectrograms/cry_detection/test\")\n",
    "save_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/model/cry_detection\")\n",
    "\n",
    "# Model hyperparameters\n",
    "img_size = (224, 224)  # MobileNetV2 input size\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 0.0001\n",
    "dropout_rate = 0.4 \n",
    "\n",
    "# Class information\n",
    "class_names = ['non-cry', 'cry']\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7dac7a",
   "metadata": {},
   "source": [
    "## 3. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96c1b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrograms(data_dir, verbose=True):\n",
    "    \"\"\"\n",
    "    Load .npy spectrograms from directory structure.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path object or string path to directory containing cry/non_cry folders\n",
    "        verbose: Print loading progress\n",
    "    \n",
    "    Returns:\n",
    "        spectrograms: numpy array of spectrograms\n",
    "        labels: numpy array of labels (0=non-cry, 1=cry)\n",
    "    \"\"\"\n",
    "\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load cry mel-spectrograms (label = 1)\n",
    "    cry_dir = data_dir / 'cry'  # Find the 'cry' subfolder\n",
    "    cry_files = list(cry_dir.glob('*.npy')) # Get all .npy files in the 'cry' folder\n",
    "    \n",
    "    for file in cry_files: # Load each cry file and label it as 1 (cry = 1, non-cry = 0)\n",
    "        spec = np.load(file) # load the .npy (mel spectrogram) file\n",
    "        spectrograms.append(spec) # add to mel-spectrograms list\n",
    "        labels.append(1) # label as cry (1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(cry_files)} cry spectrograms\")\n",
    "    \n",
    "    # Load non-cry spectrograms (label = 0)\n",
    "    non_cry_dir = data_dir / 'non-cry'\n",
    "    non_cry_files = list(non_cry_dir.glob('*.npy'))\n",
    "    \n",
    "    for file in non_cry_files:\n",
    "        spec = np.load(file)\n",
    "        spectrograms.append(spec)\n",
    "        labels.append(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(non_cry_files)} non-cry spectrograms\")\n",
    "        print(f\"Total samples: {len(spectrograms)}\")\n",
    "    \n",
    "    return np.array(spectrograms), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118bfe25",
   "metadata": {},
   "source": [
    "## 4. Prepare Mel-Spectrograms for MobileNetV2 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfba6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_mobilenet(spectrograms, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Prepare mel-spectrograms for MobileNetV2 input.\n",
    "    \n",
    "    Transforms all mel-spectrograms from (128, 32) grayscale format to (224, 224, 3) RGB format required by MobileNetV2's pre-trained weights from ImageNet.\n",
    "    \n",
    "    Process:\n",
    "    1. Input: (128, 32) - 128 mel bands x 32 time frames\n",
    "    2. Add channel: (128, 32, 1) - add dimension for grayscale\n",
    "    3. Resize: (224, 224, 1) - match MobileNetV2 input size\n",
    "    4. Repeat channels: (224, 224, 3) - convert to RGB by duplicating grayscale values\n",
    "    \n",
    "    Args:\n",
    "        spectrograms: numpy array of mel-spectrograms with shape (n_samples, 128, 32)\n",
    "        target_size: tuple (height, width) for resizing, default (224, 224)\n",
    "    \n",
    "    Returns:\n",
    "        prepared: numpy array with shape (n_samples, 224, 224, 3)\n",
    "    \"\"\"\n",
    "    prepared = []\n",
    "    \n",
    "    for spec in spectrograms:\n",
    "        # Step 1: Add channel dimension\n",
    "        # Transform from (128, 32) to (128, 32, 1)\n",
    "        # This prepares the 2D mel-spectrogram for image processing\n",
    "        if len(spec.shape) == 2:\n",
    "            spec = np.expand_dims(spec, axis=-1)  # Expand the shape of the array. Shape: (128, 32, 1)\n",
    "        \n",
    "        # Step 2: Resize to MobileNetV2's expected input size\n",
    "        # Transform from (128, 32, 1) to (224, 224, 1)\n",
    "        # Width stretches from 32 → 224 frames (7x expansion)\n",
    "        # Height expands from 128 → 224 mel bands (~1.75x expansion)\n",
    "        resized = cv2.resize(spec, target_size)  # Expand the shape of the array. Shape: (224, 224, 1)\n",
    "        \n",
    "        # Step 3: Ensure channel dimension exists after resize\n",
    "        if len(resized.shape) == 2:\n",
    "            resized = np.expand_dims(resized, axis=-1)  # Shape: (224, 224, 1)\n",
    "        \n",
    "        # Step 4: Convert grayscale (1 channel) to RGB (3 channels)\n",
    "        # Transform from (224, 224, 1) to (224, 224, 3)\n",
    "        # Creates \"fake RGB\" by duplicating the same values across R, G, B channels\n",
    "        # This allows MobileNetV2 (trained on colour images) to process the grayscale spectrograms\n",
    "        if resized.shape[-1] == 1:\n",
    "            resized = np.repeat(resized, 3, axis=-1)  # Final shape: (224, 224, 3)\n",
    "        \n",
    "        prepared.append(resized) # add to prepared list\n",
    "    \n",
    "    return np.array(prepared, dtype=np.float32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
