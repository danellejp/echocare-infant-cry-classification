{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ed6d53",
   "metadata": {},
   "source": [
    "# EchoCare: Cry Classification Model Training\n",
    "## Stage 2 of Two-Stage Pipeline\n",
    "\n",
    "This notebook trains a binary classification model to detect pain cries vs hungry cries in infants.\n",
    "\n",
    "**Dataset:**\n",
    "- Baby Chillanto Dataset \n",
    "\n",
    "**Categories:**\n",
    "- Pain\n",
    "- Hungry\n",
    "\n",
    "**Target Performance:** >70% accuracy for cry classification\n",
    "\n",
    "**Architecture:** MobileNetV2 (lightweight for Raspberry Pi deployment) with custom classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5cfd2",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d533526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e97c76",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a020f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/dataset/processed/mel-spectrograms/cry_classification/train\")\n",
    "val_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/dataset/processed/mel-spectrograms/cry_classification/validate\")\n",
    "test_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/dataset/processed/mel-spectrograms/cry_classification/test\")\n",
    "save_dir = Path(\"C:/Users/danel/FYP/echocare-infant-cry-classification/model/cry_classification\")\n",
    "\n",
    "# Model hyperparameters\n",
    "img_size = (224, 224)  # MobileNetV2 input size\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 0.0001\n",
    "dropout_rate1 = 0.3\n",
    "dropout_rate2 = 0.2\n",
    "\n",
    "# Class information\n",
    "class_names = ['pain', 'hungry']\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427be4a9",
   "metadata": {},
   "source": [
    "## 3. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrograms(data_dir, verbose=True):\n",
    "    \"\"\"\n",
    "    Load .npy spectrograms from directory structure.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path object or string path to directory containing pain/hungry folders\n",
    "        verbose: Print loading progress\n",
    "    \n",
    "    Returns:\n",
    "        spectrograms: numpy array of spectrograms\n",
    "        labels: numpy array of labels (0=pain, 1=hungry)\n",
    "    \"\"\"\n",
    "\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load hungry mel-spectrograms (label = 1)\n",
    "    hungry_dir = data_dir / 'hungry'  # Find the 'hungry' subfolder\n",
    "    hungry_files = list(hungry_dir.glob('*.npy')) # Get all .npy files in the 'hungry' folder\n",
    "    \n",
    "    for file in hungry_files: # Load each hungry file and label it as 1 (hungry = 1)\n",
    "        spec = np.load(file) # load the .npy (mel spectrogram) file\n",
    "        spectrograms.append(spec) # add to mel-spectrograms list\n",
    "        labels.append(1) # label as hungry (1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(hungry_files)} hungry spectrograms\")\n",
    "    \n",
    "    # Load pain spectrograms (label = 0)\n",
    "    pain_dir = data_dir / 'pain'\n",
    "    pain_files = list(pain_dir.glob('*.npy'))\n",
    "    \n",
    "    for file in pain_files: # Load each pain file and label it as 0 (pain = 0)\n",
    "        spec = np.load(file)\n",
    "        spectrograms.append(spec)\n",
    "        labels.append(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(pain_files)} pain spectrograms\")\n",
    "        print(f\"Total samples: {len(spectrograms)}\")\n",
    "    \n",
    "    return np.array(spectrograms), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741beeb7",
   "metadata": {},
   "source": [
    "## 4. Prepare Mel-Spectrograms for MobileNetV2 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fae54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_mobilenet(spectrograms, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Prepare mel-spectrograms for MobileNetV2 input.\n",
    "    \n",
    "    Transforms all mel-spectrograms from (128, 32) grayscale format to (224, 224, 3) RGB format required by MobileNetV2's pre-trained weights from ImageNet.\n",
    "    \n",
    "    Process:\n",
    "    1. Input: (128, 32) - 128 mel bands x 32 time frames\n",
    "    2. Add channel: (128, 32, 1) - add dimension for grayscale\n",
    "    3. Resize: (224, 224, 1) - match MobileNetV2 input size\n",
    "    4. Repeat channels: (224, 224, 3) - convert to RGB by duplicating grayscale values\n",
    "    \n",
    "    Args:\n",
    "        spectrograms: numpy array of mel-spectrograms with shape (n_samples, 128, 32)\n",
    "        target_size: tuple (height, width) for resizing, default (224, 224)\n",
    "    \n",
    "    Returns:\n",
    "        prepared: numpy array with shape (n_samples, 224, 224, 3)\n",
    "    \"\"\"\n",
    "    prepared = []\n",
    "    \n",
    "    for spec in spectrograms:\n",
    "        # Step 1: Add channel dimension\n",
    "        # Transform from (128, 32) to (128, 32, 1)\n",
    "        # This prepares the 2D mel-spectrogram for image processing\n",
    "        if len(spec.shape) == 2:\n",
    "            spec = np.expand_dims(spec, axis=-1)  # Expand the shape of the array. Shape: (128, 32, 1)\n",
    "        \n",
    "        # Step 2: Resize to MobileNetV2's expected input size\n",
    "        # Transform from (128, 32, 1) to (224, 224, 1)\n",
    "        # Width stretches from 32 → 224 frames (7x expansion)\n",
    "        # Height expands from 128 → 224 mel bands (~1.75x expansion)\n",
    "        resized = cv2.resize(spec, target_size)  # Expand the shape of the array. Shape: (224, 224, 1)\n",
    "        \n",
    "        # Step 3: Ensure channel dimension exists after resize\n",
    "        if len(resized.shape) == 2:\n",
    "            resized = np.expand_dims(resized, axis=-1)  # Shape: (224, 224, 1)\n",
    "        \n",
    "        # Step 4: Convert grayscale (1 channel) to RGB (3 channels)\n",
    "        # Transform from (224, 224, 1) to (224, 224, 3)\n",
    "        # Creates \"fake RGB\" by duplicating the same values across R, G, B channels\n",
    "        # This allows MobileNetV2 (trained on colour images) to process the grayscale spectrograms\n",
    "        if resized.shape[-1] == 1:\n",
    "            resized = np.repeat(resized, 3, axis=-1)  # Final shape: (224, 224, 3)\n",
    "        \n",
    "        prepared.append(resized) # add to prepared list\n",
    "    \n",
    "    return np.array(prepared, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd83b2",
   "metadata": {},
   "source": [
    "## 5. Load and Visualise Cry Classification (Pain vs Hungry) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "X_train_raw, y_train = load_spectrograms(train_dir)\n",
    "\n",
    "# Load validation data\n",
    "print(\"\\nLoading validation data...\")\n",
    "X_val_raw, y_val = load_spectrograms(val_dir)\n",
    "\n",
    "# Load test data\n",
    "print(\"\\nLoading test data...\")\n",
    "X_test_raw, y_test = load_spectrograms(test_dir)\n",
    "\n",
    "print(f\"Training samples: {len(X_train_raw)}\")\n",
    "print(f\"Validation samples: {len(X_val_raw)}\")\n",
    "print(f\"Test samples: {len(X_test_raw)}\")\n",
    "print(f\"Raw spectrogram shape: {X_train_raw[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cbd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise sample spectrograms\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Find 4 hungry samples (where label = 1)\n",
    "hungry_indices = np.where(y_train == 1)[0][60:64]\n",
    "\n",
    "# Find 4 pain samples (where label = 0)  \n",
    "pain_indices = np.where(y_train == 0)[0][60:64]\n",
    "\n",
    "# Plot 4 hungry samples in top row\n",
    "for i in range(4):\n",
    "    spec = X_train_raw[hungry_indices[i]]  # Get hungry mel-spectrogram (128 mel bands × 32 time frames)\n",
    "    axes[0, i].imshow(spec, aspect='auto')\n",
    "    axes[0, i].set_title(f'Hungry Sample {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Plot 4 pain samples in bottom row\n",
    "for i in range(4):\n",
    "    spec = X_train_raw[pain_indices[i]]  # Get pain mel-spectrogram (128 mel bands × 32 time frames)\n",
    "    axes[1, i].imshow(spec, aspect='auto')\n",
    "    axes[1, i].set_title(f'Pain Sample {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70574cf",
   "metadata": {},
   "source": [
    "## 6. Normalising Mel-Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalisation parameters from training set only\n",
    "mean = np.mean(X_train_raw)\n",
    "std = np.std(X_train_raw)\n",
    "\n",
    "print(f\"Training set statistics:\")\n",
    "print(f\"Mean: {mean:.2f}\")\n",
    "print(f\"Std:  {std:.2f}\")\n",
    "print(f\"Min:  {np.min(X_train_raw):.2f}\")\n",
    "print(f\"Max:  {np.max(X_train_raw):.2f}\")\n",
    "\n",
    "# Apply standardisation (z-score normalisation)\n",
    "X_train_norm = (X_train_raw - mean) / std\n",
    "X_val_norm = (X_val_raw - mean) / std\n",
    "X_test_norm = (X_test_raw - mean) / std\n",
    "\n",
    "print(\"\\nAfter normalisation:\")\n",
    "print(f\"Training mean: {np.mean(X_train_norm):.2f} \") # (should be ~0)\n",
    "print(f\"Training std:  {np.std(X_train_norm):.2f} \") # (should be ~1)\n",
    "\n",
    "# Show normalisation parameters for deployment on Raspberry Pi\n",
    "normalisation_params = {\n",
    "    \"mean\": float(mean),\n",
    "    \"std\": float(std),\n",
    "    \"method\": \"standardisation\"\n",
    "}\n",
    "\n",
    "print(normalisation_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bee5b1",
   "metadata": {},
   "source": [
    "## 7. Preparing Data for MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and convert to 3-channel format\n",
    "print(\"Preparing data for MobileNetV2\")\n",
    "\n",
    "X_train = prepare_for_mobilenet(X_train_norm, target_size=img_size) # prepare training set\n",
    "X_val = prepare_for_mobilenet(X_val_norm, target_size=img_size) # prepare validation set\n",
    "X_test = prepare_for_mobilenet(X_test_norm, target_size=img_size) # prepare test set\n",
    "\n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}\")\n",
    "print(f\"\\n  y_train: {y_train.shape}\")\n",
    "print(f\"  y_val:   {y_val.shape}\")\n",
    "print(f\"  y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2da81",
   "metadata": {},
   "source": [
    "## 8. Calculating Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "# Training set has: 245 hungry sounds, 134 pain sounds\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(\"Class weights to handle imbalance:\")\n",
    "for cls, weight in class_weights.items():\n",
    "    print(f\"{class_names[cls]}: {weight:.4f}\")\n",
    "\n",
    "print(\"\\nThis gives more importance to the minority class (pain) during training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8560a60",
   "metadata": {},
   "source": [
    "## 9. Building Cry Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cry_classification_model(input_shape=(224, 224, 3), dropout_rate1=0.3, dropout_rate2=0.2):\n",
    "    \"\"\"\n",
    "    Build MobileNetV2-based binary classifier for cry classification.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input image shape\n",
    "        dropout_rate: Dropout rate for preventing overfitting\n",
    "    \n",
    "    Returns:\n",
    "        model: Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Load MobileNetV2 (without top classification layer)\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False, # Exclude final classification layer\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu', name='dense_256')(x)\n",
    "    x = Dropout(dropout_rate1, name='dropout_1')(x)\n",
    "    x = Dense(64, activation='relu', name='dense_64')(x)\n",
    "    x = Dropout(dropout_rate2, name='dropout_2')(x)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(x)  # Binary classification\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=base_model.input, outputs=output, name='CryClassificationModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a14ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_cry_classification_model(\n",
    "    input_shape=(img_size[0], img_size[1], 3), # MobileNetV2 expects 3-channel input\n",
    "    dropout_rate1=dropout_rate1,\n",
    "    dropout_rate2=dropout_rate2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee726984",
   "metadata": {},
   "source": [
    "## 10. Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37657130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully\")\n",
    "print(f\"\\nOptimiser: Adam (lr={learning_rate})\")\n",
    "print(f\"Loss: Binary Crossentropy\")\n",
    "print(f\"Metrics: Accuracy, Precision, Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4395e09",
   "metadata": {},
   "source": [
    "## 11. Setting up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f48f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "\n",
    "    # Save best model based on validation accuracy\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(save_dir / 'best_model_classification.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    \n",
    "    # Stop training when validation loss stops improving\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=7,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"ModelCheckpoint\")\n",
    "print(\"EarlyStopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e195cac",
   "metadata": {},
   "source": [
    "## 12. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    class_weight=class_weights,  # Handle class imbalance\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c528046",
   "metadata": {},
   "source": [
    "## 13. Plotting the Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84856dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Model Accuracy')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Model Loss')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation')\n",
    "axes[1, 0].set_title('Model Precision')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train')\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation')\n",
    "axes[1, 1].set_title('Model Recall')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e80c6",
   "metadata": {},
   "source": [
    "## 14. Loading Best Model and Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a90bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model\n",
    "best_model = keras.models.load_model(save_dir / 'best_model_classification.keras') \n",
    "print(\"Best model loaded successfully\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_results = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Results on Test Set\")\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Precision: {test_results[2]:.4f}\")\n",
    "print(f\"Test Recall: {test_results[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c9521",
   "metadata": {},
   "source": [
    "## 15. Generating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b266b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "y_pred_prob = best_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Cry Classification')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix values\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives (pain correctly identified): {cm[0, 0]}\")\n",
    "print(f\"False Positives (pain wrongly as hungry): {cm[0, 1]}\")\n",
    "print(f\"False Negatives (hungry wrongly as pain): {cm[1, 0]}\")\n",
    "print(f\"True Positives (hungry correctly identified):  {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b2cd4",
   "metadata": {},
   "source": [
    "## 16. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ce73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Summary\")\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Test Accuracy: {test_results[1]*100:.2f}%\")\n",
    "print(f\"  Test Precision: {test_results[2]*100:.2f}%\")\n",
    "print(f\"  Test Recall: {test_results[3]*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
